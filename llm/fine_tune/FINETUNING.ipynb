{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from getpass import getpass     # 보안 정보를 화면에 표시 없이 입력받을 때 사용하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY = getpass('OpenAI API Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=MY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'FineTuneData/QRdataset.jsonl'\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f :\n",
    "    dataset = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에러가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors['data_type'] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get('messages', None)\n",
    "    if not messages:\n",
    "        format_errors['missing_messages_list'] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if not isinstance(message, dict):  # message가 dict인지 확인\n",
    "            format_errors['message_not_dict'] += 1\n",
    "            continue\n",
    "\n",
    "        if any(key not in ['role', 'content'] for key in message):  # 예상치 못한 키 확인\n",
    "            format_errors['message_uncrecongnized_key'] += 1\n",
    "            continue\n",
    "\n",
    "        if 'role' not in message or 'content' not in message:\n",
    "            format_errors['message_missing_key'] += 1\n",
    "\n",
    "        if message.get('role', None) not in ['system', 'user', 'assistant']:\n",
    "            format_errors['unrecognized_role'] += 1\n",
    "\n",
    "        content = message.get('content', None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors['missing_content'] += 1\n",
    "\n",
    "    if not any(message.get('role', None) == 'assistant' for message in messages):\n",
    "        format_errors['example_missing_assistant_message'] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print('에러 발견')\n",
    "    for key, value in format_errors.items():\n",
    "        print(f'{key} : {value} 개')\n",
    "else:\n",
    "    print('에러가 없습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, tokens_per_message = 3, tokens_per_name = 1) :\n",
    "    num_tokens = 0\n",
    "    for message in messages :\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items() :\n",
    "            num_tokens+= len(encoding.encode(value))\n",
    "            if key == \"name\" :\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages) :\n",
    "    num_tokens = 0\n",
    "    for message in messages :\n",
    "        if message['role'] == 'assistant' :\n",
    "            num_tokens += len(encoding.encode(message['content']))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def print_statistics(values) :\n",
    "    print(f'min / max : {min(values)}, {max(values)}')\n",
    "    print(f'mean / median : {np.mean(values)}, {np.median(values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_output_tokens = 4096       #gpt 3.5 turbo\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "total_tokens_lens = []\n",
    "assistant_message_lens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System 메시지 누락 수 : 0\n",
      "User 메시지 누락 수 : 0\n",
      "\n",
      "대화 당 메시지 수 통계 :\n",
      "min / max : 3, 3\n",
      "mean / median : 3.0, 3.0\n",
      "\n",
      "대화 당 전체 토큰 수 통계 :\n",
      "min / max : 75, 127\n",
      "mean / median : 87.51515151515152, 85.0\n",
      "\n",
      "대화 당 assistant 출력 토큰 수 통계 :\n",
      "min / max : 3, 4\n",
      "mean / median : 3.5454545454545454, 4.0\n",
      "\n",
      "0개의 대화가 4096개의 토큰 제한을 초과하여 이 부분은 학습 중 잘릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "for ex in dataset :\n",
    "    messages = ex['messages']\n",
    "\n",
    "    if not any (message['role'] == 'system' for message in messages) :\n",
    "        n_missing_system += 1\n",
    "\n",
    "    if not any (message['role'] == 'user' for message in messages) :\n",
    "        n_missing_user += 1\n",
    "\n",
    "    n_messages.append(len(messages))\n",
    "\n",
    "    total_tokens_lens.append(num_tokens_from_messages(messages))\n",
    "\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "\n",
    "print('System 메시지 누락 수 :', n_missing_system)\n",
    "print('User 메시지 누락 수 :', n_missing_user)\n",
    "print()\n",
    "print('대화 당 메시지 수 통계 :')\n",
    "print_statistics(n_messages)\n",
    "print()\n",
    "print('대화 당 전체 토큰 수 통계 :')\n",
    "print_statistics(total_tokens_lens)\n",
    "print()\n",
    "print('대화 당 assistant 출력 토큰 수 통계 :')\n",
    "print_statistics(assistant_message_lens)\n",
    "print()\n",
    "# total_tokens_lens에서 각각의 값을 16384와 비교\n",
    "n_too_long = sum(i>max_output_tokens for i in total_tokens_lens)\n",
    "print(f'{n_too_long}개의 대화가 {max_output_tokens}개의 토큰 제한을 초과하여 이 부분은 학습 중 잘릴 수 있습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS_PER_EXAMPLE = 4096      # 대화 당 최대 토큰 수 (3.5turbo 기준)\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 셋에는 학습 중 요금이 청구될 2888개의 토큰이 있습니다.\n",
      "기본적으로 이 데이터 셋에서 3 epoch 동안 학습합니다.\n",
      "총 8664개의 토큰에 대해 요금이 청구됩니다.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "\n",
    "# 만약 대화의 개수와 TARGET_EPOCHS의 곱이 최소 데이터 수보다 적다면\n",
    "if (n_train_examples * TARGET_EPOCHS) < MIN_TARGET_EXAMPLES :\n",
    "    # OpenAI테스트 기준 epochs 최대치(MIN_DEFAULT_EPOCHS)와 최소 데이터에서 우리 데이터 수(n_train_examples)를 나눈 몫을 비교하여 더 낮은 값으로 최종 학습 횟수 설정\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, (MIN_TARGET_EXAMPLES//n_train_examples))\n",
    "\n",
    "elif (n_train_examples * TARGET_EPOCHS) > MAX_TARGET_EXAMPLES :\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, (MAX_TARGET_EXAMPLES//n_train_examples))\n",
    "\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in total_tokens_lens)\n",
    "\n",
    "print(f'데이터 셋에는 학습 중 요금이 청구될 {n_billing_tokens_in_dataset}개의 토큰이 있습니다.')\n",
    "print(f'기본적으로 이 데이터 셋에서 {n_epochs} epoch 동안 학습합니다.')\n",
    "print(f'총 {n_epochs*n_billing_tokens_in_dataset}개의 토큰에 대해 요금이 청구됩니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_files = client.files.create(\n",
    "    file= open('FineTuneData/QRdataset.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "fine_tune_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_job = client.fine_tuning.jobs.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    training_file=fine_tune_files.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_job.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.retrieve(fine_tuning_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 매물을 추천해 드릴게요.  \n",
      "혹시 어떤 지역을 선호하시나요? 지역에 대한 선호도가 있으면 매물을 더 정확하게 추천해 드릴 수 있어요.\n",
      "질문\n",
      "추천\n",
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 매물을 추천해 드릴게요.  \n",
      "1. 매물 위치: 강남구 역삼동  \n",
      "   - 병원: 강남성모병원 (도보 5분 이내)\n",
      "   - 공원: 역삼동근린공원 (도보 10분 이내)\n",
      "   - 매물 종류: 아파트  \n",
      "   - 가격: 5억원  \n",
      "   - 연락처: 010-1234-5678  \n",
      "\n",
      "2. 매물 위치: 서초구 반포동  \n",
      "   - 병원: 서울아산병원 (도보 3분 이내)\n",
      "   - 공원: 반포한강공원 (도보 15분 이내)\n",
      "   - 매물 종류: 주택  \n",
      "   - 가격: 8억원  \n",
      "   - 연락처: 010-9876-5432  \n",
      "\n",
      "더 필요한 정보가 있으면 언제든지 말씀해주세요.\n",
      "질문\n",
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 지역을 찾으시는군요. 제가 추천하는 매물은 아래와 같습니다.  \n",
      "\n",
      "매물 1: 서울 강남구 언주로에 위치한 아파트  \n",
      "- 병원: 강남성모병원 (도보 5분 이내)\n",
      "- 공원: 언주역 근처의 언주고개공원 (도보 10분 이내)\n",
      "- 매물 가격: 5억원  \n",
      "\n",
      "매물 2: 부산 해운대구 해운대로에 위치한 아파트  \n",
      "- 병원: 부산해운대병원 (도보 10분 이내)\n",
      "- 공원: 동백섬 공원 (도보 15분 이내)\n",
      "- 매물 가격: 4억원  \n",
      "\n",
      "매물 3: 대구 수성구 달구벌대로에 위치한 아파트  \n",
      "- 병원: 대구파티마병원 (도보 5분 이내)\n",
      "- 공원: 수성못 공원 (도보 10분 이내)\n",
      "- 매물 가격: 3억원  \n",
      "\n",
      "위 매물 중에서 원하시는 조건에 맞는 곳이 있으면 알려주세요. 더 많은 매물을 원하시면 다시 말씀해주세요.\n",
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 매물을 찾아보시는 것이 좋겠네요. 아래 매물을 추천해드릴게요.  \n",
      "\n",
      "매물 1: 서울 강남구 언주로에 위치한 아파트  \n",
      "- 병원: 강남병원 도보 5분 거리  \n",
      "- 공원: 언주 공원 인근에 위치  \n",
      "- 매물 가격: 5억원  \n",
      "\n",
      "매물 2: 부산 해운대구 해운대해변 근처 아파트  \n",
      "- 병원: 해운대 의료원 차로 10분 거리  \n",
      "- 공원: 동백섬 공원 도보 3분 거리  \n",
      "- 매물 가격: 7억원  \n",
      "\n",
      "매물 3: 대구 수성구 공원로에 위치한 아파트  \n",
      "- 병원: 대구의료원 도보 10분 거리  \n",
      "- 공원: 수성못 공원 인근에 위치  \n",
      "- 매물 가격: 4억원  \n",
      "\n",
      "위 매물 중에서 원하시는 조건에 맞는 매물이 있으면 자세한 정보를 확인해보시는 것을 추천드립니다.\n",
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 매물을 추천해 드릴게요.  \n",
      "1. 매물 위치: 강남구 역삼동  \n",
      "   - 병원: 강남차병원 (도보 5분 이내)\n",
      "   - 공원: 역삼동 공원 (도보 10분 이내)  \n",
      "   - 가격: 5억원  \n",
      "   - 링크: [강남구 역삼동 매물 바로가기](매물 링크)\n",
      "\n",
      "2. 매물 위치: 서초구 반포동  \n",
      "   - 병원: 서초중앙병원 (도보 3분 이내)\n",
      "   - 공원: 반포한강공원 (도보 15분 이내)  \n",
      "   - 가격: 6억원  \n",
      "   - 링크: [서초구 반포동 매물 바로가기](매물 링크)\n",
      "**추천**  \n",
      "주변에 병원과 공원이 가까운 지역을 찾으시는군요. 제가 추천드리는 매물은 서울 강남구 양재동에 위치한 A 아파트입니다. 이 아파트는 주변에 다양한 의료시설과 공원이 있어 건강하고 쾌적한 환경에서 생활할 수 있습니다. 또한 대중교통이 편리하여 병원과 공원을 쉽게 이용할 수 있습니다. 자세한 내용은 매물 링크를 확인해보세요.  \n",
      "[매물 링크: A 아파트](매물 링크)\n",
      "추천\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10) :\n",
    "    completion = client.chat.completions.create(model='gpt-3.5-turbo',\n",
    "                                                messages=[{\"role\": \"system\", \"content\": \"질문과 매물 추천으로 구분하여 각각 '질문', '추천'만을 출력합니다.\"},\n",
    "                                                        {'role' : 'user', 'content' : '난 병원을 자주 가고 공원이 가까우면 좋겠어'}],\n",
    "                                                temperature=0)\n",
    "\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 8.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10) :\n",
    "    completion = client.chat.completions.create(\n",
    "    model='ft:gpt-3.5-turbo-0125:fininsight::BByIChMO',\n",
    "    messages=[\n",
    "        {'role' : 'system', 'content' : '사용자의 입력을 질문과 매물 추천 요청으로 구분하여 각각 \"질문\", \"추천\"만을 출력합니다.'},\n",
    "        {'role' : 'user', 'content' : '난 병원을 자주 가고 공원이 가까우면 좋겠어'}]\n",
    ")\n",
    "\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "추천\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10) :\n",
    "    completion = client.chat.completions.create(\n",
    "    model='ft:gpt-4o-mini-2024-07-18:fininsight::BBxvqdSu',\n",
    "    messages=[\n",
    "        {'role' : 'system', 'content' : '사용자의 입력을 질문과 매물 추천 요청으로 구분하여 각각 \"질문\", \"추천\"만을 출력합니다.'},\n",
    "        {'role' : 'user', 'content' : '난 병원을 자주 가고 공원이 가까우면 좋겠어'}]\n",
    ")\n",
    "\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
